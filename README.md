# OllamaChat

A chat interface with local LLMs using Ollama.

## Table of Contents
- [Introduction](#introduction)
- [Features](#features)
- [Installation](#installation)
  - [Prerequisites](#prerequisites)
  - [Setup](#setup)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

## Introduction
OllamaChat is a chat interface designed to work with local Language Model Machines (LLMs) using Ollama. This project aims to provide a robust chat application with support for local LLMs, ensuring privacy and performance.

## Features
- Local LLM support using Ollama
- Easy setup and deployment with Django
- Customizable chat interface
- Secure and private communication

## Installation

### Prerequisites
Before you begin, ensure you have met the following requirements:
- Python 3.x
- Django
- Ollama

### Setup

1. **Clone the Repository**
   ```sh
   git clone https://github.com/yourusername/OllamaChat.git
   cd OllamaChat


